{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E-commerce project using \n",
    "    # logistic K class without training\n",
    "    # logistic K class with training\n",
    "    # NN with training\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "%run process.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction WIHTOUT weight training\n",
    "\n",
    "X,Y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = X.shape[1]\n",
    "M = 5\n",
    "K = len(set(Y)) # unique values in Y (classes)\n",
    "\n",
    "# we are using random weights since we dont know how to train them yet\n",
    "W1 = np.random.randn(D,M)\n",
    "b1 = np.random.randn(M)\n",
    "W2 = np.random.randn(M,K)\n",
    "b2 = np.random.randn(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    expa = np.exp(a)\n",
    "    Y = expa / expa.sum(axis=1, keepdims=True)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    return 1/(1+np.exp(-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,W1,b1,W2,b2):\n",
    "    Y = np.tanh(X.dot(W1) + b1)\n",
    "    return softmax(Y.dot(W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_Y_given_X = forward(X,W1,b1,W2,b2)\n",
    "P = np.argmax(P_Y_given_X,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_rate(Y,P):\n",
    "    return np.mean(Y==P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification rate: 0.048\n"
     ]
    }
   ],
   "source": [
    "print(f\"classification rate: {classification_rate(Y,P)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will train weights using gradient descent \n",
    "# this is not NN. this is logistic regression with K classes\n",
    "# lets call this logistic softmax train\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y2_indicator(Y,K):\n",
    "    N = len(Y)\n",
    "    ind = np.zeros((N,K))\n",
    "    for i in range(N):\n",
    "        ind[i,Y[i]] = 1\n",
    "    \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 8) (8, 4) (4,)\n"
     ]
    }
   ],
   "source": [
    "X,Y = get_data()\n",
    "X,Y = shuffle(X,Y)\n",
    "Y = Y.astype(np.int32)\n",
    "D = X.shape[1]\n",
    "K = len(set(Y))\n",
    "\n",
    "Xtrain = X[:-100]\n",
    "Ytrain = Y[:-100]\n",
    "Ytrain_ind = y2_indicator(Ytrain,K)\n",
    "\n",
    "Xtest = X[-100:]\n",
    "Ytest = Y[-100:]\n",
    "Ytest_ind = y2_indicator(Ytest,K)\n",
    "\n",
    "# initializing random weights\n",
    "W = np.random.randn(D,K)\n",
    "b = np.zeros(K)\n",
    "\n",
    "print(Xtrain.shape, W.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_K(X,W,b):\n",
    "    return softmax(X.dot(W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(P_Y_given_X):\n",
    "    return np.argmax(P_Y_given_X,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(T,pY):\n",
    "    return -np.mean(T*np.log(pY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0854557711112079 0.06695425490918257\n",
      "1000 0.08544924052815527 0.06694028466342723\n",
      "2000 0.08544367957682991 0.06692672042306874\n",
      "3000 0.08543891518545323 0.06691354417465123\n",
      "4000 0.0854348093175652 0.06690074474151672\n",
      "5000 0.08543125110737426 0.06688831495066111\n",
      "6000 0.08542815093353204 0.06687624978452486\n",
      "7000 0.08542543591017755 0.06686454519330168\n",
      "8000 0.08542304642593511 0.06685319735080669\n",
      "9000 0.0854209334657913 0.06684220220765648\n",
      "train classification rate: 0.9025\n",
      "test classification rate: 0.9\n"
     ]
    }
   ],
   "source": [
    "def logistic_kclass_train(Xtrain,Xtest,Ytrain,Ytrain_ind,Ytest_ind,Ytest,W,b):\n",
    "    train_costs = []\n",
    "    test_costs = []\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    for i in range(10000):\n",
    "        pYtrain = forward_K(Xtrain,W,b)\n",
    "        pYtest = forward_K(Xtest,W,b)\n",
    "\n",
    "        ctrain = cross_entropy(Ytrain_ind,pYtrain)\n",
    "        ctest = cross_entropy(Ytest_ind,pYtest)\n",
    "        train_costs.append(ctrain)\n",
    "        test_costs.append(ctest)\n",
    "\n",
    "        W -= learning_rate*Xtrain.T.dot(pYtrain-Ytrain_ind)\n",
    "        b -= learning_rate*(pYtrain-Ytrain_ind).sum(axis=0)\n",
    "\n",
    "        if i%1000==0:\n",
    "            print(i, ctrain, ctest)\n",
    "\n",
    "    print(f\"train classification rate: {classification_rate(Ytrain,predict(pYtrain))}\")\n",
    "    print(f\"test classification rate: {classification_rate(Ytest,predict(pYtest))}\")\n",
    "\n",
    "    # legend1, = plt.plot(train_costs, label='train cost')\n",
    "    # legend2, = plt.plot(test_costs, label='test cost')\n",
    "    # plt.legend([legend1, legend2])\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    # so we see that the accuracy is much better than when the weights\n",
    "    # were not trained. But we still did a little worse than binary \n",
    "    # classification\n",
    "    \n",
    "logistic_kclass_train(Xtrain,Xtest,Ytrain,Ytrain_ind,Ytest_ind,Ytest,W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will train a Neural Network to make predictions for our \n",
    "# E-commerce project\n",
    "\n",
    "M = 5 # number of hidden units\n",
    "\n",
    "# we already have train and test sets\n",
    "\n",
    "# initializing weights randomly\n",
    "W1 = np.random.rand(D,M)\n",
    "b1 = np.zeros(M)\n",
    "W2 = np.random.rand(M,K)\n",
    "b2 = np.zeros(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also have to return Y\n",
    "def forward_nn(X,W1,b1,W2,b2):\n",
    "    Y = np.tanh(X.dot(W1) + b1)\n",
    "    return softmax(Y.dot(W2) + b2),Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.02484182356844605 0.07509124045364164\n",
      "1000 0.02472697697743325 0.07646035977379734\n",
      "2000 0.024616880504109484 0.0778580746972598\n",
      "3000 0.024508551770181172 0.0793042981018471\n",
      "4000 0.02439800087826988 0.08079689127759059\n",
      "5000 0.024279548263767124 0.08231875030599946\n",
      "6000 0.024143912841937332 0.08386208137790079\n",
      "7000 0.023970381516570095 0.08543102436795642\n",
      "8000 0.023775156440979276 0.08702011973515673\n",
      "9000 0.023638413459328596 0.08855215174280494\n",
      "train classification rate: 0.965\n",
      "test classification rate: 0.91\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A single argument passed to legend() must be a list of labels, but found an Artist in there.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-88ff6fafc124>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mNN_kclass_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtrain_ind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtest_ind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-86-88ff6fafc124>\u001b[0m in \u001b[0;36mNN_kclass_train\u001b[1;34m(Xtrain, Xtest, Ytrain, Ytrain_ind, Ytest_ind, Ytest, W1, b1, W2, b2)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mlegend1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_costs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train cost'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mlegend2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_costs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test cost'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlegend1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegend2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mlegend\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2736\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2737\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2738\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mlegend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgallery\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtext_labels_and_annotations\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \"\"\"\n\u001b[1;32m--> 411\u001b[1;33m         handles, labels, extra_args, kwargs = mlegend._parse_legend_args(\n\u001b[0m\u001b[0;32m    412\u001b[0m                 \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\matplotlib\\legend.py\u001b[0m in \u001b[0;36m_parse_legend_args\u001b[1;34m(axs, handles, labels, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1197\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mArtist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1199\u001b[1;33m             raise TypeError(\"A single argument passed to legend() must be a \"\n\u001b[0m\u001b[0;32m   1200\u001b[0m                             \"list of labels, but found an Artist in there.\")\n\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: A single argument passed to legend() must be a list of labels, but found an Artist in there."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# main train loop\n",
    "\n",
    "def NN_kclass_train(Xtrain,Xtest,Ytrain,Ytrain_ind,Ytest_ind,Ytest,W1,b1,W2,b2):\n",
    "    train_costs = []\n",
    "    test_costs = []\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    for i in range(10000):\n",
    "        pYtrain, Ztrain = forward_nn(Xtrain,W1,b1,W2,b2)\n",
    "        pYtest, Ztest = forward_nn(Xtest,W1,b1,W2,b2)\n",
    "        \n",
    "        ctrain = cross_entropy(Ytrain_ind,pYtrain)\n",
    "        ctest = cross_entropy(Ytest_ind,pYtest)\n",
    "        train_costs.append(ctrain)\n",
    "        test_costs.append(ctest)\n",
    "        \n",
    "        W2 -= learning_rate*Ztrain.T.dot(pYtrain-Ytrain_ind)\n",
    "        b2 -= learning_rate*(pYtrain-Ytrain_ind).sum()\n",
    "        dz = (pYtrain-Ytrain_ind).dot(W2.T)*(1-Ztrain*Ztrain)\n",
    "        W1 -= learning_rate*(Xtrain.T.dot(dz))\n",
    "        b1 -= learning_rate*dz.sum(axis=0)\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(i, ctrain, ctest)\n",
    "            \n",
    "    print(f\"train classification rate: {classification_rate(Ytrain,predict(pYtrain))}\")\n",
    "    print(f\"test classification rate: {classification_rate(Ytest,predict(pYtest))}\")\n",
    "    \n",
    "    legend1, = plt.plot(train_costs, label='train cost')\n",
    "    legend2, = plt.plot(test_costs, label='test cost')\n",
    "    plt.legend([legend1, legend2])\n",
    "    plt.show()\n",
    "    \n",
    "NN_kclass_train(Xtrain,Xtest,Ytrain,Ytrain_ind,Ytest_ind,Ytest,W1,b1,W2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
